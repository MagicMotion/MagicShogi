name: "Aoba"

layer {
  name: "data"
  type: "MemoryData"
  top: "data"
  top: "dummy_label1"
  memory_data_param {
    batch_size: 128
    channels: 362
    height: 9
    width: 9
  }
}
layer {
  name: "label_policy"
  type: "MemoryData"
  top: "p_label"
  top: "dummy_label2"
  memory_data_param {
    batch_size: 128
    channels: 2187
    height: 1
    width: 1
  }
}
layer {
  name: "flat_policy_label"
  type: "Flatten"
  bottom: "p_label"
  top: "label_policy"
}

layer {
  name: "label_value"
  type: "MemoryData"
  top: "label_value"
  top: "dummy_label3"
  memory_data_param {
    batch_size: 128
    channels: 1
    height: 1
    width: 1
  }
}

layer {
  name:"silence"
  type:"Silence"
# dummy_label1,2,3 must be 0. not to print log
  bottom: "dummy_label1"
  bottom: "dummy_label2"
  bottom: "dummy_label3"
}


#this part should be the same in learning and prediction network
layer {
  name: "conv1_3x3_192"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    weight_filler { type: "msra" }
    bias_filler { type: "constant" }
  }
}
layer {
  name: "bn1"
  type: "BatchNorm"
  bottom: "conv1"
  top: "bn1"
}
layer {
  name: "mish1/bnll"
  type: "BNLL"
  bottom:"bn1"
  top: "mish1/bnll"
}
layer {
  name: "mish1/tanh"
  type: "TanH"
  bottom:"mish1/bnll"
  top: "mish1/tanh"
}
layer {
  name: "mish1"
  type: "Eltwise"
  bottom:"bn1"
  bottom: "mish1/tanh"
  top:"mish1"
  eltwise_param { operation: PROD }
}

# ResNet starts from conv2.  conv2 and conv3 are one block.

layer {
  name:"conv2_3x3_192"
  type:"Convolution"
  bottom:"mish1"
  top:"conv2"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    weight_filler { type:"msra" }
    bias_filler { type:"constant" }
  }
}
layer {
  name:"bn2"
  type:"BatchNorm"
  bottom:"conv2"
  top:"bn2"
}
layer {
  name: "mish2/bnll"
  type: "BNLL"
  bottom:"bn2"
  top: "mish2/bnll"
}
layer {
  name: "mish2/tanh"
  type: "TanH"
  bottom:"mish2/bnll"
  top: "mish2/tanh"
}
layer {
  name: "mish2"
  type: "Eltwise"
  bottom:"bn2"
  bottom: "mish2/tanh"
  top:"mish2"
  eltwise_param { operation: PROD }
}
layer {
  name:"conv3_3x3_192"
  type:"Convolution"
  bottom:"mish2"
  top:"conv3"
  convolution_param {
    num_output: 192
    kernel_size: 3
    pad: 1
    weight_filler { type:"msra" }
    bias_filler { type:"constant" }
  }
}
layer {
  name:"bn3"
  type:"BatchNorm"
  bottom:"conv3"
  top:"bn3"
}
layer {
  name:"elt3"
  type:"Eltwise"
  bottom:"mish1"
  bottom:"bn3"
  top:"sum3"
  eltwise_param { operation: SUM }
}
layer {
  name: "mish3/bnll"
  type: "BNLL"
  bottom:"sum3"
  top: "mish3/bnll"
}
layer {
  name: "mish3/tanh"
  type: "TanH"
  bottom:"mish3/bnll"
  top: "mish3/tanh"
}
layer {
  name: "mish3"
  type: "Eltwise"
  bottom:"sum3"
  bottom: "mish3/tanh"
  top:"mish3"
  eltwise_param { operation: PROD }
}
layer {
  name:"conv4_3x3_192"
  type:"Convolution"
  bottom:"mish3"
  top:"co